

Tokenization isÂ **the process of converting plaintext into a token value which does not reveal the sensitive data being tokenized**. The token is of the same length and format as the plaintext, and that plaintext and token are stored in a secure token vault, if one is in use.